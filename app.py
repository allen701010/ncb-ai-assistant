import streamlit as st
from google import genai
from google.genai import types

# 1. é é¢é…ç½®
st.set_page_config(page_title="NCB CAN HELP - å¯¦é©—å‹•ç‰©å°ˆæ¥­åŠ©ç†", layout="wide")

# 2. åˆå§‹åŒ–å°è©±ç´€éŒ„
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# 3. å´é‚Šæ¬„è¨­å®š
with st.sidebar:
    st.title("âš™ï¸ è¨­å®šä¸­å¿ƒ")
    api_key = st.secrets.get("GEMINI_API_KEY") or st.text_input("è¼¸å…¥ Gemini API Key", type="password")
    
    # åŠ å…¥æ¸…é™¤ç´€éŒ„æŒ‰éˆ•ï¼Œæœ‰æ•ˆé™ä½ TPM æ¶ˆè€—
    if st.button("ğŸ§¹ æ¸…é™¤å°è©±ç´€éŒ„"):
        st.session_state.chat_history = []
        st.rerun()
        
    st.markdown("---")
    st.info("ğŸ’¡ æç¤ºï¼šè‹¥é‡åˆ° 429 éŒ¯èª¤ï¼Œè«‹é»æ“Šä¸Šæ–¹æŒ‰éˆ•æ¸…é™¤ç´€éŒ„ä¸¦ç¨å€™ä¸€åˆ†é˜ã€‚")

# 4. é–å®šæŒ‡å¼•æ ¸å¿ƒå…§å®¹
SYSTEM_INSTRUCTION = """ä½ æ˜¯ 'NCB CAN HELP' AI åŠ©ç†ï¼Œå°ˆé–€æ ¹æ“š 2018 ç‰ˆã€Šå¯¦é©—å‹•ç‰©ç…§è­·åŠä½¿ç”¨æŒ‡å¼•ã€‹æä¾›è«®è©¢ã€‚
ã€æ ¸å¿ƒçŸ¥è­˜é»ã€‘
1. 3Rsç²¾ç¥ï¼šæ›¿ä»£ (Replacement)ã€æ¸›é‡ (Reduction)ã€ç²¾ç·»åŒ– (Refinement)ã€‚
2. ç’°å¢ƒæ¨™æº–ï¼šå°é¼ ã€å¤§é¼ å»ºè­°æº«åº¦ 20-26Â°Cã€‚
3. ç–¼ç—›è©•ä¼°ï¼šåˆ†æ•¸é” 15-20 åˆ†æ‡‰è€ƒæ…®äººé“å®‰æ¨‚æ­»ã€‚
4. å®‰æ¨‚æ­»ç¦å¿Œï¼šCO2 é ˆä½¿ç”¨é«˜å£“æ¡¶è£æ°£é«”ï¼Œåš´ç¦ä¹¾å†°ã€‚"""

st.title("ğŸ¾ NCB å¯ä»¥æä¾›å”åŠ©")
st.subheader("å¯¦é©—å‹•ç‰©ç…§é¡§åŠä½¿ç”¨æŒ‡å¼• AI é¡§å•")

# 5. ğŸ’¡ å¿«é€ŸæŸ¥è©¢æŒ‰éˆ•
st.write("### ğŸ’¡ å¿«é€ŸæŸ¥è©¢")
col1, col2, col3, col4 = st.columns(4)
quick_query = None

with col1:
    if st.button("ğŸŒ¡ï¸ ç’°å¢ƒæº«åº¦è¦ç¯„"): quick_query = "è«‹åˆ—å‡ºå¸¸è¦‹å¯¦é©—å‹•ç‰©çš„ç’°å¢ƒå»ºè­°æº«åº¦ç¯„åœã€‚"
with col2:
    if st.button("ğŸ§¬ 3R åŸå‰‡å®šç¾©"): quick_query = "è«‹è§£é‡‹æŒ‡å¼•ä¸­æ›¿ä»£ã€æ¸›é‡åŠç²¾ç·»åŒ–çš„å®šç¾©ã€‚"
with col3:
    if st.button("âš–ï¸ ç–¼ç—›åˆ†ç´šæ¨™æº–"): quick_query = "æ ¹æ“šæŒ‡å¼•é™„ä»¶äºŒï¼Œå¦‚ä½•è©•ä¼°å¤§é¼ ç–¼ç—›ç­‰ç´šï¼Ÿ"
with col4:
    if st.button("ğŸš« å®‰æ¨‚æ­»ç¦å¿Œ"): quick_query = "æŒ‡å¼•ç¦æ­¢å“ªäº›ä¸äººé“å®‰æ¨‚æ­»ï¼ŸCO2æœ‰é™åˆ¶å—ï¼Ÿ"

# é¡¯ç¤ºæ­·å²ç´€éŒ„
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]): 
        st.markdown(msg["content"])

# 6. è™•ç†è¼¸å…¥ (ä½¿ç”¨æœ€ç©©å®šæ¨¡å‹åç¨±)
user_input = st.chat_input("è©¢å•æŒ‡å¼•å…§å®¹...")
prompt = user_input or quick_query

if prompt:
    if not api_key:
        st.error("è«‹åœ¨ Secrets è¨­å®š GEMINI_API_KEYï¼")
        st.stop()
    
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    with st.chat_message("user"): 
        st.markdown(prompt)

    try:
        client = genai.Client(api_key=api_key)
        with st.chat_message("assistant"):
            with st.spinner("AI æ­£åœ¨æŸ¥é–±æŒ‡å¼•..."):
                response = client.models.generate_content(
                    model='gemini-2.0-flash-exp', 
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        system_instruction=SYSTEM_INSTRUCTION,
                        temperature=0.1
                    )
                )
                st.markdown(response.text)
                st.session_state.chat_history.append({"role": "assistant", "content": response.text})
    except Exception as e:
        # é‡å° 429 éŒ¯èª¤æä¾›å‹å–„æç¤º
        if "429" in str(e):
            st.error("âš ï¸ æµé‡å·²é”ä¸Šé™ï¼šè«‹é»æ“Šå·¦å´ã€Œæ¸…é™¤å°è©±ç´€éŒ„ã€ä¸¦ç­‰å¾…ä¸€åˆ†é˜å¾Œå†è©¦ã€‚")
        else:
            st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

st.markdown("---")
st.caption("âš ï¸ å…è²¬è²æ˜ï¼šæœ¬ AI åƒ…ä¾›åƒè€ƒï¼Œæ‰€æœ‰è™•ç½®æ‡‰ä»¥æ©Ÿæ§‹ IACUC æ ¸å‡†ç‰ˆæœ¬ç‚ºæº–ã€‚")