import streamlit as st
from google import genai
from google.genai import types
from openai import OpenAI

# 1. é é¢é…ç½®
st.set_page_config(page_title="NCB CAN HELP - å¯¦é©—å‹•ç‰©å°ˆæ¥­åŠ©ç†", layout="wide")

# 2. åˆå§‹åŒ–å°è©±ç´€éŒ„
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# 3. å´é‚Šæ¬„è¨­å®š
with st.sidebar:
    st.title("âš™ï¸ è¨­å®šä¸­å¿ƒ")
    # å¾ Secrets è®€å–é‡‘é‘°
    gemini_api_key = st.secrets.get("GEMINI_API_KEY") or st.text_input("è¼¸å…¥ Gemini API Key", type="password", key="gemini_key")
    openrouter_api_key = st.secrets.get("OPENROUTER_API_KEY") or st.text_input("è¼¸å…¥ OpenRouter API Key (å‚™æ´)", type="password", key="openrouter_key")
    
    # è¨ºæ–·èˆ‡æ¸…ç†å·¥å…·
    col_diag, col_clear = st.columns(2)
    with col_diag:
        if st.button("ğŸ” æª¢æŸ¥é€£ç·š"):
            status_msgs = []
            # æª¢æŸ¥ Gemini
            if gemini_api_key:
                try:
                    test_client = genai.Client(api_key=gemini_api_key)
                    models = test_client.models.list()
                    status_msgs.append("âœ… Gemini é€£ç·šæˆåŠŸ")
                except Exception as e:
                    status_msgs.append(f"âŒ Gemini é€£ç·šå¤±æ•—: {e}")
            else:
                status_msgs.append("âš ï¸ æœªè¨­å®š Gemini Key")
            
            # æª¢æŸ¥ OpenRouter
            if openrouter_api_key:
                try:
                    test_or_client = OpenAI(
                        base_url="https://openrouter.ai/api/v1",
                        api_key=openrouter_api_key
                    )
                    test_or_client.models.list()
                    status_msgs.append("âœ… OpenRouter é€£ç·šæˆåŠŸ")
                except Exception as e:
                    status_msgs.append(f"âŒ OpenRouter é€£ç·šå¤±æ•—: {e}")
            else:
                status_msgs.append("âš ï¸ æœªè¨­å®š OpenRouter Key (å‚™æ´)")
            
            for msg in status_msgs:
                if "âœ…" in msg:
                    st.success(msg)
                elif "âŒ" in msg:
                    st.error(msg)
                else:
                    st.warning(msg)
    
    with col_clear:
        if st.button("ğŸ§¹ æ¸…é™¤ç´€éŒ„"):
            st.session_state.chat_history = []
            st.rerun()
            
    st.markdown("---")
    st.info("ğŸ’¡ æç¤ºï¼šæœ¬åŠ©ç†å„ªå…ˆä½¿ç”¨ Gemini å…è²»é¡åº¦ï¼ˆæŒ‰ RPD/RPM/TPM æ’åºï¼‰ï¼Œç”¨ç›¡å¾Œè‡ªå‹•åˆ‡æ›ä»˜è²»æˆ– OpenRouterã€‚")

# 4. æŒ‡å¼•æ ¸å¿ƒå…§å®¹é–å®š
SYSTEM_INSTRUCTION = """ä½ æ˜¯ 'NCB CAN HELP' AI åŠ©ç†ï¼Œæ ¹æ“š 2018 ç‰ˆã€Šå¯¦é©—å‹•ç‰©ç…§è­·åŠä½¿ç”¨æŒ‡å¼•ã€‹å›ç­”ã€‚
1. 3Rsç²¾ç¥ï¼šæ›¿ä»£ã€æ¸›é‡ã€ç²¾ç·»åŒ–ã€‚
2. ç’°å¢ƒï¼šå°é¼ å¤§é¼ æº«åº¦ 20-26Â°Cï¼Œæ›æ°£ 10-15 æ¬¡/å°æ™‚ã€‚
3. ç–¼ç—›ï¼šåˆ†æ•¸é” 15-20 åˆ†æ‡‰è€ƒæ…®äººé“å®‰æ¨‚æ­»ã€‚
4. ç¦å¿Œï¼šCO2 é ˆé«˜å£“æ¡¶è£ï¼Œåš´ç¦ä¹¾å†°ã€‚"""

st.title("ğŸ¾ NCB å¯ä»¥æä¾›å”åŠ©")
st.subheader("å¯¦é©—å‹•ç‰©ç…§é¡§åŠä½¿ç”¨æŒ‡å¼• AI é¡§å• (æ™ºæ…§è·¯ç”±ç‰ˆ)")

# 5. å¿«é€ŸæŸ¥è©¢æŒ‰éˆ•
st.write("### ğŸ’¡ å¿«é€ŸæŸ¥è©¢")
btn_cols = st.columns(4)
queries = [
    ("ğŸŒ¡ï¸ ç’°å¢ƒæº«åº¦è¦ç¯„", "è«‹åˆ—å‡ºå¸¸è¦‹å¯¦é©—å‹•ç‰©çš„ç’°å¢ƒå»ºè­°æº«åº¦ç¯„åœã€‚"),
    ("ğŸ§¬ 3R åŸå‰‡å®šç¾©", "è«‹è§£é‡‹æŒ‡å¼•ä¸­æ›¿ä»£ã€æ¸›é‡åŠç²¾ç·»åŒ–çš„å®šç¾©ã€‚"),
    ("âš–ï¸ ç–¼ç—›åˆ†ç´šæ¨™æº–", "æ ¹æ“šæŒ‡å¼•é™„ä»¶äºŒï¼Œå¦‚ä½•è©•ä¼°å¤§é¼ ç–¼ç—›ç­‰ç´šï¼Ÿ"),
    ("ğŸš« å®‰æ¨‚æ­»ç¦å¿Œ", "æŒ‡å¼•ç¦æ­¢å“ªäº›ä¸äººé“å®‰æ¨‚æ­»ï¼ŸCO2æœ‰é™åˆ¶å—ï¼Ÿ")
]
quick_query = None
for i, (label, q_text) in enumerate(queries):
    if btn_cols[i].button(label): quick_query = q_text

# é¡¯ç¤ºæ­·å²ç´€éŒ„
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

# 6. æ¨¡å‹å„ªå…ˆé †åºå®šç¾© (æŒ‰ RPD/RPM/TPM ç”±é«˜åˆ°ä½æ’åº)
# å…è²»æ¨¡å‹å„ªå…ˆé †åºï¼š
#   1. gemini-2.5-flash-lite-preview: 1000 RPD, 15 RPM, 250K TPM (å…è²»é¡åº¦æœ€é«˜)
#   2. gemini-2.0-flash: 200 RPD, 10 RPM, 1M TPM (é«˜ TPM)
#   3. gemini-2.5-flash-preview: 250 RPD, 10 RPM, 250K TPM
#   4. gemini-2.5-pro-preview: 50 RPD, 2 RPM, 125K TPM (å…è²»è¼ƒå°‘)
# ä»˜è²»å‚™æ´ï¼šé€é OpenRouter ä½¿ç”¨ç›¸åŒæ¨¡å‹

FREE_MODEL_PRIORITY = [
    {
        'model_id': 'gemini-2.5-flash-lite-preview',
        'display_name': 'Gemini 2.5 Flash Lite',
        'tier': 'å…è²»',
        'rpd': 1000,
        'rpm': 15,
        'tpm': 250000
    },
    {
        'model_id': 'gemini-2.0-flash',
        'display_name': 'Gemini 2.0 Flash',
        'tier': 'å…è²»',
        'rpd': 200,
        'rpm': 10,
        'tpm': 1000000
    },
    {
        'model_id': 'gemini-2.5-flash-preview',
        'display_name': 'Gemini 2.5 Flash',
        'tier': 'å…è²»',
        'rpd': 250,
        'rpm': 10,
        'tpm': 250000
    },
    {
        'model_id': 'gemini-2.5-pro-preview',
        'display_name': 'Gemini 2.5 Pro',
        'tier': 'å…è²»',
        'rpd': 50,
        'rpm': 2,
        'tpm': 125000
    }
]

# OpenRouter ä»˜è²»å‚™æ´æ¨¡å‹å°æ‡‰
OPENROUTER_MODEL_MAP = {
    'gemini-2.5-flash-lite-preview': 'google/gemini-2.5-flash-preview',  # Lite ç„¡å°æ‡‰ï¼Œç”¨ Flash
    'gemini-2.0-flash': 'google/gemini-2.0-flash-exp:free',
    'gemini-2.5-flash-preview': 'google/gemini-2.5-flash-preview',
    'gemini-2.5-pro-preview': 'google/gemini-2.5-pro-preview'
}

# 7. API å‘¼å«å‡½æ•¸
def call_gemini_api(client, model_id, prompt, system_instruction):
    """ä½¿ç”¨ Google Gemini API å‘¼å«"""
    res = client.models.generate_content(
        model=model_id,
        contents=prompt,
        config=types.GenerateContentConfig(system_instruction=system_instruction, temperature=0.1)
    )
    return res.text

def call_openrouter_api(api_key, model_id, prompt, system_instruction):
    """ä½¿ç”¨ OpenRouter API å‘¼å« (OpenAI ç›¸å®¹æ ¼å¼)"""
    client = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=api_key
    )
    
    or_model = OPENROUTER_MODEL_MAP.get(model_id, 'google/gemini-2.0-flash-exp:free')
    
    response = client.chat.completions.create(
        model=or_model,
        messages=[
            {"role": "system", "content": system_instruction},
            {"role": "user", "content": prompt}
        ],
        temperature=0.1
    )
    return response.choices[0].message.content

# 8. è‡ªå‹•è·¯ç”±è™•ç†é‚è¼¯
user_input = st.chat_input("è©¢å•æŒ‡å¼•å…§å®¹...")
prompt = user_input or quick_query

if prompt:
    if not gemini_api_key and not openrouter_api_key:
        st.error("è«‹è¨­å®šè‡³å°‘ä¸€å€‹ API Key (Gemini æˆ– OpenRouter)ï¼")
        st.stop()
    
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    try:
        response_text = None
        used_model = ""
        api_source = ""
        model_tier = ""
        all_gemini_exhausted = False

        with st.chat_message("assistant"):
            with st.spinner("æŸ¥é–±æŒ‡å¼•ä¸­..."):
                # éšæ®µä¸€ï¼šæŒ‰å„ªå…ˆé †åºå˜—è©¦ Gemini å…è²»æ¨¡å‹
                if gemini_api_key:
                    client = genai.Client(api_key=gemini_api_key)
                    
                    for model_info in FREE_MODEL_PRIORITY:
                        model_id = model_info['model_id']
                        try:
                            response_text = call_gemini_api(client, model_id, prompt, SYSTEM_INSTRUCTION)
                            used_model = model_info['display_name']
                            api_source = "Gemini"
                            model_tier = model_info['tier']
                            break
                        except Exception as e:
                            error_str = str(e)
                            # 429 = é…é¡ç”¨ç›¡, 404 = æ¨¡å‹ä¸å­˜åœ¨, è³‡æºç”¨ç›¡ç­‰
                            if "429" in error_str or "404" in error_str or "RESOURCE_EXHAUSTED" in error_str:
                                st.warning(f"âš ï¸ {model_info['display_name']} é…é¡ç”¨ç›¡ (RPD:{model_info['rpd']}/RPM:{model_info['rpm']})ï¼Œåˆ‡æ›ä¸‹ä¸€å€‹...")
                                continue
                            else:
                                raise e
                    
                    # æ‰€æœ‰å…è²» Gemini æ¨¡å‹éƒ½å¤±æ•—
                    if not response_text:
                        all_gemini_exhausted = True
                        st.warning("âš ï¸ æ‰€æœ‰ Gemini å…è²»æ¨¡å‹é…é¡å·²ç”¨ç›¡ï¼Œæ­£åœ¨åˆ‡æ›è‡³ OpenRouter å‚™æ´...")
                
                # éšæ®µäºŒï¼šå¦‚æœ Gemini é…é¡ç”¨ç›¡æˆ–ç„¡ Keyï¼Œä½¿ç”¨ OpenRouter å‚™æ´
                if (all_gemini_exhausted or not gemini_api_key) and openrouter_api_key:
                    for model_info in FREE_MODEL_PRIORITY:
                        model_id = model_info['model_id']
                        try:
                            response_text = call_openrouter_api(openrouter_api_key, model_id, prompt, SYSTEM_INSTRUCTION)
                            used_model = model_info['display_name']
                            api_source = "OpenRouter"
                            model_tier = "å‚™æ´"
                            break
                        except Exception as e:
                            error_str = str(e)
                            if "429" in error_str or "404" in error_str or "rate" in error_str.lower():
                                st.warning(f"âš ï¸ OpenRouter {model_info['display_name']} ç„¡æ³•ä½¿ç”¨ï¼Œå˜—è©¦ä¸‹ä¸€å€‹...")
                                continue
                            else:
                                raise e

                if response_text:
                    # é¡¯ç¤ºä½¿ç”¨çš„æ¨¡å‹è³‡è¨Š
                    if api_source == "Gemini":
                        source_icon = "ğŸŸ¢"
                        tier_label = "Gemini API"
                    else:
                        source_icon = "ğŸŸ "
                        tier_label = "å‚™æ´ API"
                    
                    st.caption(f"âœ¨ {used_model} ({source_icon} {tier_label})")
                    st.markdown(response_text)
                    st.session_state.chat_history.append({"role": "assistant", "content": response_text})
                else:
                    st.error("âŒ æ‰€æœ‰ API é…é¡çš†å·²è€—ç›¡ï¼Œè«‹ç¨å¾Œå†è©¦æˆ–æª¢æŸ¥æ‚¨çš„ API Key è¨­å®šã€‚")

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

st.markdown("---")
st.caption("âš ï¸ å…è²¬è²æ˜ï¼šæœ¬ AI æä¾›è³‡è¨Šåƒ…ä¾›åƒè€ƒï¼Œä¸ä»£è¡¨å®˜æ–¹è¡Œæ”¿è™•åˆ†ã€‚")