import streamlit as st
from google import genai
from google.genai import types

# 1. é é¢é…ç½®
st.set_page_config(page_title="NCB CAN HELP - å¯¦é©—å‹•ç‰©å°ˆæ¥­åŠ©ç†", layout="wide")

# 2. åˆå§‹åŒ–å°è©±ç´€éŒ„
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# 3. å´é‚Šæ¬„è¨­å®š
with st.sidebar:
    st.title("âš™ï¸ è¨­å®šä¸­å¿ƒ")
    # å¾ Secrets è®€å–é‡‘é‘°
    api_key = st.secrets.get("GEMINI_API_KEY") or st.text_input("è¼¸å…¥ Gemini API Key", type="password")
    
    # è¨ºæ–·èˆ‡æ¸…ç†å·¥å…·
    col_diag, col_clear = st.columns(2)
    with col_diag:
        if st.button("ğŸ” æª¢æŸ¥é€£ç·š"):
            if api_key:
                try:
                    test_client = genai.Client(api_key=api_key)
                    models = test_client.models.list()
                    st.success("âœ… é€£ç·šæˆåŠŸ")
                except Exception as e: st.error(f"é€£ç·šå¤±æ•—: {e}")
            else: st.warning("è«‹å…ˆè¨­å®š Key")
    
    with col_clear:
        if st.button("ğŸ§¹ æ¸…é™¤ç´€éŒ„"):
            st.session_state.chat_history = []
            st.rerun()
            
    st.markdown("---")
    st.info("ğŸ’¡ æç¤ºï¼šæœ¬åŠ©ç†æœƒå„ªå…ˆä½¿ç”¨å…è²»é¡åº¦ï¼Œè‹¥æµé‡éè¼‰å°‡è‡ªå‹•åˆ‡æ›è‡³é«˜éšæ¨¡å‹ã€‚")

# 4. æŒ‡å¼•æ ¸å¿ƒå…§å®¹é–å®š
SYSTEM_INSTRUCTION = """ä½ æ˜¯ 'NCB CAN HELP' AI åŠ©ç†ï¼Œæ ¹æ“š 2018 ç‰ˆã€Šå¯¦é©—å‹•ç‰©ç…§è­·åŠä½¿ç”¨æŒ‡å¼•ã€‹å›ç­”ã€‚
1. 3Rsç²¾ç¥ï¼šæ›¿ä»£ã€æ¸›é‡ã€ç²¾ç·»åŒ–ã€‚
2. ç’°å¢ƒï¼šå°é¼ å¤§é¼ æº«åº¦ 20-26Â°Cï¼Œæ›æ°£ 10-15 æ¬¡/å°æ™‚ã€‚
3. ç–¼ç—›ï¼šåˆ†æ•¸é” 15-20 åˆ†æ‡‰è€ƒæ…®äººé“å®‰æ¨‚æ­»ã€‚
4. ç¦å¿Œï¼šCO2 é ˆé«˜å£“æ¡¶è£ï¼Œåš´ç¦ä¹¾å†°ã€‚"""

st.title("ğŸ¾ NCB å¯ä»¥æä¾›å”åŠ©")
st.subheader("å¯¦é©—å‹•ç‰©ç…§é¡§åŠä½¿ç”¨æŒ‡å¼• AI é¡§å• (è‡ªå‹•è·¯ç”±ç‰ˆ)")

# 5. å¿«é€ŸæŸ¥è©¢æŒ‰éˆ•
st.write("### ğŸ’¡ å¿«é€ŸæŸ¥è©¢")
btn_cols = st.columns(4)
queries = [
    ("ğŸŒ¡ï¸ ç’°å¢ƒæº«åº¦è¦ç¯„", "è«‹åˆ—å‡ºå¸¸è¦‹å¯¦é©—å‹•ç‰©çš„ç’°å¢ƒå»ºè­°æº«åº¦ç¯„åœã€‚"),
    ("ğŸ§¬ 3R åŸå‰‡å®šç¾©", "è«‹è§£é‡‹æŒ‡å¼•ä¸­æ›¿ä»£ã€æ¸›é‡åŠç²¾ç·»åŒ–çš„å®šç¾©ã€‚"),
    ("âš–ï¸ ç–¼ç—›åˆ†ç´šæ¨™æº–", "æ ¹æ“šæŒ‡å¼•é™„ä»¶äºŒï¼Œå¦‚ä½•è©•ä¼°å¤§é¼ ç–¼ç—›ç­‰ç´šï¼Ÿ"),
    ("ğŸš« å®‰æ¨‚æ­»ç¦å¿Œ", "æŒ‡å¼•ç¦æ­¢å“ªäº›ä¸äººé“å®‰æ¨‚æ­»ï¼ŸCO2æœ‰é™åˆ¶å—ï¼Ÿ")
]
quick_query = None
for i, (label, q_text) in enumerate(queries):
    if btn_cols[i].button(label): quick_query = q_text

# é¡¯ç¤ºæ­·å²ç´€éŒ„
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

# 6. è‡ªå‹•è·¯ç”±è™•ç†é‚è¼¯
user_input = st.chat_input("è©¢å•æŒ‡å¼•å…§å®¹...")
prompt = user_input or quick_query

if prompt:
    if not api_key:
        st.error("è«‹åœ¨ Secrets è¨­å®š GEMINI_API_KEYï¼")
        st.stop()
    
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    # å®šç¾©è·¯ç”±å„ªå…ˆé †åº
    model_priority = [
        'gemini-2.0-flash-exp',      # 1. å…è²»å„ªå…ˆ
        'gemini-3-flash-preview',    # 2. ä»˜è²» Flash å‚™æ´
        'gemini-3-pro-preview'       # 3. æœ€çµ‚ Pro æ–¹æ¡ˆ
    ]

    try:
        client = genai.Client(api_key=api_key)
        response = None
        used_model = ""

        with st.chat_message("assistant"):
            with st.spinner("æŸ¥é–±æŒ‡å¼•ä¸­..."):
                for model_id in model_priority:
                    try:
                        res = client.models.generate_content(
                            model=model_id,
                            contents=prompt,
                            config=types.GenerateContentConfig(system_instruction=SYSTEM_INSTRUCTION, temperature=0.1)
                        )
                        response = res
                        used_model = model_id
                        break
                    except Exception as e:
                        # åªæœ‰é‡åˆ°é…é¡ç”¨ç›¡(429)æˆ–æ¨¡å‹ä¸å­˜åœ¨(404)æ™‚æ‰é¡¯ç¤ºæç¤ºä¸¦åˆ‡æ›
                        if "429" in str(e) or "404" in str(e):
                            st.warning(f"âš ï¸ {model_id} ç›®å‰ç„¡æ³•ä½¿ç”¨ï¼ˆé…é¡ç”¨ç›¡æˆ–ç¶­è­·ä¸­ï¼‰ï¼Œæ­£åœ¨è‡ªå‹•åˆ‡æ›è‡³ä¸‹ä¸€é †ä½æ¨¡å‹...")
                            continue
                        else: raise e

                if response:
                    st.caption(f"âœ¨ é©…å‹•æ¨¡å‹: {used_model}")
                    st.markdown(response.text)
                    st.session_state.chat_history.append({"role": "assistant", "content": response.text})
                else:
                    st.error("âŒ æ‰€æœ‰æ¨¡å‹é…é¡çš†å·²è€—ç›¡ï¼Œè«‹é»æ“Šã€Œæ¸…é™¤ç´€éŒ„ã€ä¸¦ç­‰ä¸€åˆ†é˜å¾Œå†è©¦ã€‚")

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

st.markdown("---")
st.caption("âš ï¸ å…è²¬è²æ˜ï¼šæœ¬ AI æä¾›è³‡è¨Šåƒ…ä¾›åƒè€ƒï¼Œä¸ä»£è¡¨å®˜æ–¹è¡Œæ”¿è™•åˆ†ã€‚")